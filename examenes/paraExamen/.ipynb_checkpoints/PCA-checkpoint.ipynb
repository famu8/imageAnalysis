{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f9ab6e-f79c-4bb1-ae76-5d70f5740f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629f4d73-de6a-46c9-a713-26c5fe335272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "in_dir=\"./data\"\n",
    "txt_name=\"/irisdata.txt\"\n",
    "data = np.loadtxt(in_dir + txt_name, comments=\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1162358d-9f26-480b-8907-b2a1414151b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_iris = data[0:150, 0:4]\n",
    "#cambiamos la data porque la 5 columna es el tipo de flor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0111e875-aa40-42d5-a67c-b684bf02cb03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37100e24-24a9-4e9c-b494-326633744996",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b344a507-b74e-4bec-9549-8f9b9fc0bd42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "240f4942-7b6d-4c24-b93d-d559861888fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92461872 0.05306648 0.01710261 0.00521218]\n",
      "The first two principal components explain 100.00% of the total variation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standardize the data by dividing each measurement by its standard deviation\n",
    "standardized_data = StandardScaler().fit_transform(data)\n",
    "\n",
    "\n",
    "print(\"-----\")\n",
    "print(standardized_data[0,0])\n",
    "print(\"-----\")\n",
    "\n",
    "# Perform PCA\n",
    "# n_components=2\n",
    "pca = PCA()\n",
    "principal_components = pca.fit_transform(standardized_data)\n",
    "\n",
    "# Calculate the explained variance ratio for each principal component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Display the explained variance ratios\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"Explained Variance Ratio for Principal Component {i + 1}: {ratio}\")\n",
    "\n",
    "# Calculate the cumulative explained variance up to the first two principal components\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "print(\"Cumulative Explained Variance for the First Two Principal Components:\", cumulative_explained_variance[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadee32a-7668-4979-87ec-e4a761a4d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esto es [0]. el primerPC, [2] el primero + el segundo , etc...\n",
    "cumulative_explained_variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c4e34b-0773-4f0a-ae68-fa81a7e48e46",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### primero del dataset en el pca space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda4945-cc85-41ff-98ae-81292466a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the coordinates of the first car in the PCA space\n",
    "coordinates_first_car = principal_components[0, :]\n",
    "\n",
    "# Calculate the absolute value of the first coordinate\n",
    "absolute_value_first_coordinate = np.abs(coordinates_first_car[0])\n",
    "\n",
    "# Display the result\n",
    "print(\"Absolute Value of the First Coordinate of the First Car in PCA Space:\", absolute_value_first_coordinate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b823da6-a175-484a-b510-5ebf5b2a57ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e071446c-128a-4067-8ce1-9213684660c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names for the dataframe\n",
    "columns = ['wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'horsepower', 'highway-mpg']\n",
    "\n",
    "# Create a pandas DataFrame with the standardized car data\n",
    "df = pd.DataFrame(StandardScaler().fit_transform(data), columns=columns)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()\n",
    "principal_components = pca.fit_transform(df)\n",
    "\n",
    "# Create a new DataFrame with the first three principal components\n",
    "df_pca = pd.DataFrame(data=principal_components[:, :3], columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "# Concatenate the first three measurements to the DataFrame\n",
    "df_pca[['wheel-base', 'length', 'width']] = df[['wheel-base', 'length', 'width']]\n",
    "\n",
    "# Create a pair plot\n",
    "sns.pairplot(df_pca, vars=['PC1', 'PC2', 'PC3'], hue=None)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c1e75-e5e6-4231-b3b7-39a288552a45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# para IMAGENES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507da69-5060-4f6a-9680-790c9947e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explained_variance_by_components(imagenes, num_componentes):\n",
    "    \"\"\"\n",
    "    Calcula la variación total explicada por un número dado de componentes principales.\n",
    "\n",
    "    :param imagenes: Una matriz donde cada columna es una imagen.\n",
    "    :param num_componentes: El número de componentes principales para estudiar.\n",
    "    :return: La variación total explicada por los componentes principales especificados.\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=num_componentes)\n",
    "    pca.fit(imagenes)\n",
    "\n",
    "    variacion_total_explicada = np.sum(pca.explained_variance_ratio_)\n",
    "\n",
    "    return variacion_total_explicada\n",
    "\n",
    "ruta_base = './data/car'\n",
    "extension = '.jpg'\n",
    "imagenes_grises = []\n",
    "\n",
    "# //////////////////convertir la iamgen a un stack de imagenes////////////////////////\n",
    "for i in range(1, 6):\n",
    "    ruta_imagen = ruta_base + str(i) + extension\n",
    "    imagen = cv2.imread(ruta_imagen, cv2.IMREAD_GRAYSCALE)\n",
    "    imagenes_grises.append(imagen)\n",
    "matriz_imagenes = np.column_stack([imagen.flatten() for imagen in imagenes_grises])\n",
    "# //////////////////////////////////////////////\n",
    "\n",
    "num_componentes = 1  # Número de componentes principales a estudiar\n",
    "variacion_total = explained_variance_by_components(matriz_imagenes, num_componentes)\n",
    "\n",
    "print(f\"Variación total explicada por {num_componentes} componentes principales: {variacion_total:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b6d090-7a6d-4934-8917-0a92facfd519",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# pca imagenes jesus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dea2eb-3302-4045-98d9-de07ac669b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the image files from the directory\n",
    "preprocess_dir = r\"C:\\Users\\jdiaz\\Desktop\\DTU_ImageAnalysis\\Exams\\Fall2021\\ImagePCA_1\"\n",
    "files = glob.glob(f\"{preprocess_dir}/*.png\")\n",
    "\n",
    "# We create a matrix containing all the images and flatten it\n",
    "print(io.imread(files[0]).shape)\n",
    "height, width = io.imread(files[0]).shape\n",
    "data_matrix = np.zeros((len(files), height * width))\n",
    "for i, f in enumerate(files):\n",
    "    data_matrix[i, :] = io.imread(f).flatten()\n",
    "\n",
    "\n",
    "print(\"Computing PCA\")\n",
    "orchids_pca = decomposition.PCA()\n",
    "orchids_pca.fit(data_matrix)\n",
    "\n",
    "components = orchids_pca.transform(data_matrix)\n",
    "print(components.shape)\n",
    "pc_1 = components[:,0] \n",
    "print(pc_1.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming you have obtained the first principal component as a 1D array\n",
    "# Let's assume pc is the 1D array\n",
    "\n",
    "# Reshape the 1D array into a 2D image with dimensions (400x533)\n",
    "image_dimensions = (400, 533)\n",
    "first_principal_component_image = pc_1.reshape(height,width)\n",
    "\n",
    "# Access the value at position (row=10, column=10) in the 1-based matrix coordinate system\n",
    "row_1_based = 10 - 1  # Convert to 0-based system\n",
    "column_1_based = 10 - 1  # Convert to 0-based system\n",
    "\n",
    "value_at_10_10 = first_principal_component_image[9,9]\n",
    "\n",
    "print(f\"Value at (row=10, column=10) in the 1-based matrix coordinate system: {value_at_10_10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768f2f1-ac26-4600-8a61-a37db6ae8365",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# matematicas en pca \n",
    "si te piden sumar medias o cosas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c660138-16fc-417e-9d25-634aad0438c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_gabr = PCA()\n",
    "pca_result = pca_gabr.fit(data)\n",
    "\n",
    "pc1 = pca_gabr.components_[0]\n",
    "pc1 = pca_gabr.components_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fac97f-a4ff-4720-9d59-a9443584d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(data, axis=0)\n",
    "new_pizza = 3* pc1 + mean\n",
    "print(new_pizza)\n",
    "# esto te daria una nueva pizza con las cosas de pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe6d4c0-1508-428a-ad26-0a067f3e4162",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
